# Target capture data

## Background

Much of the information in this chapter is drawn from the HybPiper tutorial, which can be found at https://github.com/mossmatters/HybPiper/wiki/Tutorial

```{bash, echo=FALSE, eval=FALSE}
also see tutorials at
https://hackmd.io/@mossmatters?utm_source=preview-mode&utm_medium=rec
https://hackmd.io/@mossmatters/SJLQRQTGY
https://hackmd.io/@mossmatters/HkPM7pwEK
```

First make a folder in your home directory to hold your outputs for this component of the project.

```{bash, echo=FALSE, eval=FALSE}
sudo conda create -p /mnt/homes4celsrs/shared/envs/hybpiper -c chrisjackson-pellicle hybpiper
```

We have pre-installed the program HybPiper, which assembles target sequences from short high-throughput DNA sequencing reads. 
By assembling each target sequence for each species we will be able to produce a dataset that allows us to understand the evolutionary history of the species.

To access HybPiper run.
This activates a conda environment (don't worry about this!).

```
conda activate /mnt/homes4celsrs/shared/envs/hybpiper
```

In this case, our target sequences are the Angiosperm 353 standard targets. 
Target capture is a standard technique for sequencing many known loci simultaneously using a library of sequences. 
We have provided you with low-coverage sequence data from using these target sequences as probes (your fastq files).
HybPiper first assigns each read to a particular target using alignment software (BWA).
These reads are then assembled using a standard genome assembler (Spades).
HybPiper outputs a fasta file of the (in frame) CDS portion of each sample for each target region.

## Running HybPiper to assemble genes

The basic command for HybPiper is as follows:

```
hybpiper assemble -t_dna targets.fasta -r species1_R*_test.fastq --prefix species1 --bwa --cpu 3
```

Notice the commands and flags.
Move to the results directory in your workshop directory to run the following commands.
You should run this command, with the following changes:

* The argument for t_dna is the fasta file in the shared workshop folder - you will need to indicate a full relative path not just the file name
* The argument for the the r flag is the filename(s) including paths for the fastq files of interest. Note the * indicates that we will use both pairs of the sequencing read files. 
* The prefix should be indicative of the species name
* Note that we are sharing a server so we are specifying 3 cpu's per group - if you are running on your own machine you can omit this flag and HybPiper will use all available resources. With limited shared resources this run may take a few minutes.

To view your results, list the contents of the folder and folders inside this.
You should see a folder for each gene.
Within each folder you can see several fasta files, which you can view. 

To automatically run all samples consecutively you will need to loop through them.
Go back and look at the prior example of loops.
One approach is to make a list of all the names of the species in a file and then read that and use them one at a time.

First we need to make the list. We want to automate this process because in some cases you could have a lot of samples. Additionally, copying and pasting names into a list is prone to error. 
Additionally, once you automate this process you could repeat it easily and quickly for other datasets.
For starters make a list of just the R1 files (you don't want R2 files because they have the same name so you would have duplicates). 
First cd back to your data folder.
Output your list to a file in your results folder named `namelist.txt` by "redirecting" the output using `>`.

```
ls *R1* > ~/evolution_workshop/results/namelist.txt 
```

Check that this worked using `cat` or by viewing the file and counting the number of lines..
We will need to adjust this output do remove the R1 label so that we can use wildcards to list both files together.
One approach is to notice a pattern in filenames: the files start with a sample identifier followed by an underscore followed by another identifier.
Thus, we can "cut off" all of the name after the second underscore and still have a unique name for our sample.
We use the "cut" command to make our data into columns using _ (specify a delimiter with -d), then we select the first two of these (use the field flag -f).

```
ls *R1* | cut -d '_' -f 1,2 > ~/evolution_workshop/results/namelist.txt 
```

Check this worked.
Now we can run HybPiper on all of our data sequentially.
In the following example, the species names are entered in the namelist.txt file.
The loop will iterate through them one at a time and run HybPiper.

```
while read name
do 
    [insert command here]
done < [path to]/namelist.txt
```

## Process outputs

To obtain some information about the results of this process use the `hybpiper stats` command as follows.

```
hybpiper stats -t_dna [target file] gene [path to]/namelist.txt
```

From https://hackmd.io/@mossmatters/HkPM7pwEK#Getting-HybPiper-Stats

Hybpiper stats will generate two files, seq_lengths.tsv and hybpiper_stats.tsv.
The first line of seq_lengths.tsv has the names of each gene. 
The second line has the length of the target gene, averaged over each "source" for that gene. 
The rest of the lines are the length of the sequence recovered by HybPiper for each gene. If there was no sequence for a gene, a 0 is entered.

### Viewing information

While you can `cat` or `head` this file it is difficult to view this information on the command line.
However, R is excellent for reading data in this format.

* Click the Console tab
* While you could run commands here as you have in the shell, instead we will create a script to keep track of all of your commands. Note that this is also possible in the shell.
* Select File - New File - R script
* Save this file in the scripts folder

To analyze data in `R` we need to load some helper "libraries". A common library for analysis is the `tidyverse`, which wraps multiple libraries made by RStudio. For details and cheatsheets see https://www.tidyverse.org/

Put the following in your script then click the Run icon.

```
library(tidyverse)
```

Note: R assumes you are in your project folder so all paths should be relative to this.

As for our work in shell we will use commands that require arguments. 
However, the format is slightly different.
We will use the `read.table` command.
In this case arguments are placed in parentheses following the command.
We have three arguments: the filename (including path), how the columns are separated, and whether the file has a header line.
Additionally, when we read the file into memory we assign the information to a "variable".
You can think of the variable as a box to contain the information

```
stats <- read.table("results/hybpiper_stats.tsv", sep = "\t", header = TRUE)
```

When you run this command you will see the data saved in the environment.
When you click on the variable in the environment you will be able to view the data in tabular format.
We will work more extensively with data like this later.

Repeat this analysis for `seq_lengths.tsv`.

Given your observation of the output tables, you may be interested in some of the following questions:

* What are the min, max, and average number of genes retrieved across samples?
* What is the range of lengths retrieved for a given gene?

You should take a look at the data and imagine how you would calculate this.
Unfortunately,this process (e.g. calculating the min value of each column individually) could be challenging to communicate to the computer effectively.
Furthermore, when we look at data in this "rectangular" form, we often want to ensure that our
data are "tidy".
Tidy data usually has one sample per row.
Currently our data have many observations per gene per row.
If we were to look at the lengths file and make a new row that includes our 
calculation of the standard deviation of the gene lengths this would be a row with summary
information not sample information.

Instead of working with these data frames directly we are going to take a look at an example
that I have made for you that includes stats for just two samples in "long form."

* Read the file in the shared workshop folder using the `read_csv` command.
* Take a look at how these data are organized. Can you see how the data are organized that each row contains one piece of information?

The first thing we can do is visualize the variation in the data.
We use the command `ggplot` and provide the data and the independent and dependent variables we expect on the graph.

```
ggplot(stats_example, aes(stat, value))
```

Note that the variables are provided in an extra function `aes`.

If you run this command it will generate an empty plot. To plot the points you have to "add" a "layer" on this base of the plot style. In this case we use the `geom_point` function to add the data as a scatter plot.

```
ggplot(stats_example, aes(stat, value)) + geom_point()
```

We can add a couple of tweaks to make our view better. First we can specify that we want each sample to be a different color. Second we can rotate the graph 90 degrees to better view the data and labels.

```
ggplot(stats_example, aes(stat, value, color = Name)) + geom_point() + coord_flip()
```

We can also generate a summary table with one row per stat and information in that row including the mean, standard deviation, etc. across genes.

The first component of this is to develop groups of rows by stat.
I like to imagine this as drawing boxes around all rows that contain a particular stat.
We use the `group_by` function to communicate to the computer these "boxes".

```
group_by(stats_example, stat)
```

If you run this command the data won't appear to be any different.
Now we need to generate a summary table where each group is collapsed into a single row in our new table containing the stat, its average, and standard deviation.

```
mean_stats <- group_by(stats_example, stat) %>% summarize(mean_across_species = mean(value),
                                                       sd = sd(value))
```

Note that here we use `%>%` as the pipe command to send the output of one command to the next.
You have send the shell pipe `|` and this works the same way. In our summarize command we provide
new column labels and what the contents of these columns will be.

Click on your `mean_stats` variable to view your summary table.

In order to work with your lengths table you need to know how to produce a long format table.
This is tricky and will take some practice so don't worry if it seems complicated initially.
We will use the `pivot_longer` function.
If you haven't noticed already, when you type a function and hit the tab button on your keyboard you will see a list of arguments. 
The first argument you need is the data.
The second argument is the list of columns that will not be in the long table and currently contain the observation data.
For us this is all the columns from NumReads to GenesWithChimeraWarning.
Now we need to envision our new table. Go back and look at the example table for some help here.
I specified a table with a column to indicate the particular stat we are measuring and 
a second column for the actual value observed.
This command, with these four arguments looks like the following:

```
stats_long <- pivot_longer(stats, cols = NumReads:GenesWithChimeraWarning, names_to = 'stat', values_to = 'value')
```

Now try to work with the lengths table. First make a long format table. You want to output a table with the columns Species, gene, and length.

Did you notice that the mean lengths are already included in this table? That's really useful but also these data are not information about each sample and if we want to make summary tables and graphs we don't want to include them. 

We can use the `filter` command to only include data that doesn't specify MeanLength in the Species column.

```
lengths_long_filtered <- filter(lengths_long, Species != "MeanLength")
```

Now can you filter this output to include only data where the value in the length column is greater than 0.

```{bash, echo=FALSE, eval=FALSE}
lengths_long_filtered <- filter(lengths_long, Species != "MeanLength") %>% filter(length >0)
```

* Now you should be able to make a summary table including the the mean length per gene, standard deviation of length per gene, and count of genes. Note that we did our second filtering step so these values would be accurate. Additionally, the counting function is `n()` (no arguments required).

```{bash, echo=FALSE, eval=FALSE}
mean_lengths <- group_by(lengths_long_f, gene) %>% summarize(mean_length = mean(length),
                                                             sd = sd(length),
                                                             n = n())
```                                                          

Save your script!

### Obtain gene data

At this point, we will go back to our Terminal.
Remind yourself of your folders and data and note each sequence is in its own folder.
We can use HybPiper to fetch the sequences recovered for the same gene from multiple samples and generate a file for each gene. Use the following command:

```
hybpiper retrieve_sequences dna -t_dna [target file]  --sample_names [path to]/namelist.txt
```

You should now see one file per gene in your results folder.
Each file is fasta formatted with the data for each available species.
In the next section we will create an alignment of all species for each gene.

Note that HybPiper has additional features we will not use in this workshop due to a lack of time.


## Visual inspection of data

To check that your genes assembled correctly and are likely the correct species you may use BLAST, which is found at https://blast.ncbi.nlm.nih.gov/Blast.cgi

* Select Nucleotide BLAST
* Paste one of the contigs from one of the genes from one of the species
* Select Somewhat similar sequences (blastn)
* BLAST
* Examine the species and the match
